{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Scaling\n",
    "Data scaling is a pre-processing step that transforms the values of numeric variables to have desirable properties for analysis or modeling. \n",
    "\n",
    "There are different methods of data scaling, such as normalization and standardization. \n",
    "\n",
    "Data scaling can improve the stability and performance of some machine learning algorithms, especially deep learning neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StandardScaler (Standardization)\n",
    "\n",
    "This is the most famous process, in which the minus-average value (meo) is subdivided by the standard deviation (sigma)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X :  [[0, 0], [0, 0], [1, 1], [1, 1]]\n",
      "\n",
      "new_X \n",
      " [[-1. -1.]\n",
      " [-1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#----------------------------------------------------\n",
    "\n",
    "#Standard Scaler for Data\n",
    "X = [[0, 0], [0, 0], [1, 1], [1, 1]]\n",
    "scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "new_X = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "#showing dataa\n",
    "print('X : ' , X[:10])\n",
    "print('\\nnew_X \\n' , new_X[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X :  [[230, 1085], [1301, 25650], [1351, 11], [10, 12]]\n",
      "\n",
      "new_X \n",
      " [[-0.81051822 -0.51156398]\n",
      " [ 0.95026275  1.73066442]\n",
      " [ 1.0324654  -0.60959586]\n",
      " [-1.17220993 -0.60950458]]\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#----------------------------------------------------\n",
    "\n",
    "#Standard Scaler for Data\n",
    "X = [[230, 1085], [1301, 25650], [1351, 11], [10, 12]]\n",
    "scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "new_X = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "#showing dataa\n",
    "print('X : ' , X[:10])\n",
    "print('\\nnew_X \\n' , new_X[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MinMaxScaler(Normalization)\n",
    "\n",
    "\n",
    "In which the value is subtracted minus the average on the range, which is the difference between the largest and the smallest value,\n",
    "\n",
    " and the proxy of the numbers is so that it is zero to one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X \n",
      " [[230, 1085], [1301, 25650], [1351, 11], [10, 12]]\n",
      "y \n",
      " [[1.64056674e-01 4.18893093e-02]\n",
      " [9.62714392e-01 1.00000000e+00]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 3.90030812e-05]]\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#----------------------------------------------------\n",
    "\n",
    "#MinMaxScaler for Data\n",
    "\n",
    "scaler = MinMaxScaler(copy=True, feature_range=(0, 1))\n",
    "new_X = scaler.fit_transform(X)\n",
    "\n",
    "#showing data\n",
    "print('X \\n' , X[:10])\n",
    "print('y \\n' , new_X[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizer\n",
    "It is intended to eat each row separately in two-dimensional matrices\n",
    "The Normalizer class supports three different types of normalization:\n",
    "\n",
    "* L1 normalization: This type of normalization scales each sample so that the sum of the absolute values of all the elements in the sample is equal to 1.\n",
    "\n",
    "* L2 normalization: This type of normalization scales each sample so that the sum of the squares of all the elements in the sample is equal to 1.\n",
    "\n",
    "* Max normalization: This type of normalization scales each sample so that the maximum absolute value of all the elements in the sample is equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X \n",
      " [[230, 1085], [1301, 25650], [1351, 11], [10, 12]]\n",
      "y \n",
      " [[0.17490494 0.82509506]\n",
      " [0.04827279 0.95172721]\n",
      " [0.99192364 0.00807636]\n",
      " [0.45454545 0.54545455]]\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "from sklearn.preprocessing import Normalizer\n",
    "#----------------------------------------------------\n",
    "\n",
    "#Normalizing Data\n",
    "\n",
    "scaler = Normalizer(copy=True, norm='l1') # you can change the norm to 'l1' or 'max' \n",
    "new_X = scaler.fit_transform(X)\n",
    "\n",
    "#showing data\n",
    "print('X \\n' , X[:10])\n",
    "print('y \\n' , new_X[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X \n",
      " [[230, 1085], [1301, 25650], [1351, 11], [10, 12]]\n",
      "y \n",
      " [[0.20737348 0.97826185]\n",
      " [0.05065613 0.99871615]\n",
      " [0.99996685 0.00814185]\n",
      " [0.6401844  0.76822128]]\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "from sklearn.preprocessing import Normalizer\n",
    "#----------------------------------------------------\n",
    "\n",
    "#Normalizing Data\n",
    "\n",
    "scaler = Normalizer(copy=True, norm='l2') \n",
    "new_X = scaler.fit_transform(X)\n",
    "\n",
    "#showing data\n",
    "print('X \\n' , X[:10])\n",
    "print('y \\n' , new_X[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X \n",
      " [[230, 1085], [1301, 25650], [1351, 11], [10, 12]]\n",
      "y \n",
      " [[0.21198157 1.        ]\n",
      " [0.05072125 1.        ]\n",
      " [1.         0.00814212]\n",
      " [0.83333333 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "from sklearn.preprocessing import Normalizer\n",
    "#----------------------------------------------------\n",
    "\n",
    "#Normalizing Data\n",
    "\n",
    "scaler = Normalizer(copy=True, norm='max')\n",
    "new_X = scaler.fit_transform(X)\n",
    "\n",
    "#showing data\n",
    "print('X \\n' , X[:10])\n",
    "print('y \\n' , new_X[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MaxAbsScaler\n",
    "is a transformer that can be used to scale features by their maximum absolute value.\n",
    "\n",
    "This means that the maximum absolute value of each feature will be equal to 1.0. It does not shift/center the data,\n",
    " \n",
    "and thus does not destroy any sparsity. This scaler can also be applied to sparse CSR or CSC matrices.\n",
    "\n",
    "scaled_feature = feature / max_abs_value\n",
    "\n",
    "where:\n",
    "* scaled_feature is the scaled feature\n",
    "* feature is the original feature\n",
    "* max_abs_value is the maximum absolute value of the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X \n",
      " [[1.0, 10.0, 2.0], [2.0, 0.0, 0.0], [5.0, 1.0, -1.0]]\n",
      "y \n",
      " [[ 0.2  1.   1. ]\n",
      " [ 0.4  0.   0. ]\n",
      " [ 1.   0.1 -0.5]]\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "#----------------------------------------------------\n",
    "\n",
    "#MaxAbsScaler Data\n",
    "X = [[ 1., 10., 2.],\n",
    "     [ 2., 0., 0.],\n",
    "     [ 5., 1., -1.]]\n",
    "scaler = MaxAbsScaler(copy=True)\n",
    "new_X = scaler.fit_transform(X)\n",
    "\n",
    "#showing data\n",
    "print('X \\n' , X[:10])\n",
    "print('y \\n' , new_X[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FunctionTransformer \n",
    "is a transformer that can be used to apply an arbitrary function to the data. This can be useful for performing custom transformations on the data, \n",
    "\n",
    "such as taking the logarithm of the features, or adding a custom offset to each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X \n",
      " [[1.0, 10.0, 2.0], [2.0, 0.0, 0.0], [5.0, 1.0, -1.0]]\n",
      "y \n",
      " [[  1. 100.   4.]\n",
      " [  4.   0.   0.]\n",
      " [ 25.   1.   1.]]\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "#----------------------------------------------------\n",
    "\n",
    "#Function Transforming Data\n",
    "'''\n",
    "FunctionTransformer(func=None, inverse_func=None, validate= None,\n",
    "                    accept_sparse=False,pass_y='deprecated', check_inverse=True,\n",
    "                    kw_args=None,inv_kw_args=None)\n",
    "'''\n",
    "\n",
    "scaler = FunctionTransformer(func = lambda x: x**2 , validate = True ) # or func = function1\n",
    "new_X = scaler.fit_transform(X)\n",
    "\n",
    "#showing data\n",
    "print('X \\n' , X[:10]) \n",
    "print('y \\n' , new_X[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.        , 1.        , 1.41421356, 1.41421356],\n",
       "       [1.        , 1.73205081, 3.        , 1.73205081],\n",
       "       [2.23606798, 2.64575131, 2.23606798, 1.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "X = [[4, 1, 2, 2], [1, 3, 9, 3], [5, 7, 5, 1]]\n",
    "\n",
    "def function1(z):\n",
    "    return np.sqrt(z)\n",
    "\n",
    "FT = FunctionTransformer(func = function1)\n",
    "FT.fit(X)\n",
    "newdata = FT.transform(X)\n",
    "newdata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binarizer\n",
    " it converts continuous data into binary data. This can be useful for machine learning algorithms that are sensitive to noise, such as decision trees.\n",
    "\n",
    "The Binarizer class takes a threshold as its argument.\n",
    "\n",
    "The threshold is the value that determines whether a feature will be converted to 0 or 1.\n",
    " \n",
    "Features that are less than or equal to the threshold will be converted to 0, and features that are greater than the threshold will be converted to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X \n",
      " [[1.0, -1.0, -2.0], [2.0, 0.0, -1.0], [0.0, 1.0, -1.0]]\n",
      "y \n",
      " [[0. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "from sklearn.preprocessing import Binarizer\n",
    "#----------------------------------------------------\n",
    "\n",
    "#Binarizing Data\n",
    "X = [[ 1., -1., -2.],[ 2., 0., -1.], [ 0., 1., -1.]]\n",
    "scaler = Binarizer(threshold = 1.0)\n",
    "new_X = scaler.fit_transform(X)\n",
    "\n",
    "#showing data\n",
    "print('X \\n' , X[:10])\n",
    "print('y \\n' ,new_X[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PolynomialFeatures\n",
    "can be used to create polynomial features from existing features. This can be useful for machine learning algorithms that are not linear in the original features,\n",
    "\n",
    " such as support vector machines (SVMs) and decision trees.\n",
    "\n",
    "The PolynomialFeatures class takes a degree as its argument. The degree is the highest power of the features that will be included in the new polynomial features. \n",
    "\n",
    "For example, if the degree is 2, then the new polynomial features will include the original features, as well as the square of each feature.\n",
    "\n",
    "It's specific to the work of new Fitchers, it's the current Fitchers multiplier product in the polonomic way, so if it were grade 2, for example, and we had already only two columns, or 2 Fitchers, it would give us the order:\n",
    "1, a, b, a^2, ab, b^2.\n",
    "Where number 1 in the first to hit it in Theta Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old X \n",
      " [[0 1]\n",
      " [2 3]\n",
      " [4 5]]\n",
      "\n",
      "X1 \n",
      " [[ 1.  0.  1.  0.  0.  1.]\n",
      " [ 1.  2.  3.  4.  6.  9.]\n",
      " [ 1.  4.  5. 16. 20. 25.]]\n",
      "\n",
      "X2 \n",
      " [[ 1.  0.  1.  0.]\n",
      " [ 1.  2.  3.  6.]\n",
      " [ 1.  4.  5. 20.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "X = np.arange(6).reshape(3, 2)\n",
    "print(\"old X \\n\",X)\n",
    "\n",
    "poly = PolynomialFeatures(degree=2 , include_bias = True)\n",
    "print(\"\\nX1 \\n\",poly.fit_transform(X))\n",
    "\n",
    "poly = PolynomialFeatures(interaction_only=True)\n",
    "# If the interaction_only is selected as a True value, it will only display a values multiplied by b and delete the foundations for the sole values.\n",
    "print(\"\\nX2 \\n\",poly.fit_transform(X))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
